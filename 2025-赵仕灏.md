# 2025-赵仕灏
-----------------------------------------------------
## 2025年11月3日 赵仕灏
### 学习进度
1. 更改模型为简化版的双边滤波器，在代码中创建了高斯核
    ```python
    def get_gaussian_kernel(sigma, kernel_size=5):
    """创建高斯核"""
    x = torch.arange(kernel_size).float() - kernel_size // 2
    kernel_1d = torch.exp(-x ** 2 / (2 * sigma ** 2))
    kernel_1d = kernel_1d / kernel_1d.sum()
    kernel_2d = kernel_1d.view(1, -1) * kernel_1d.view(-1, 1)
    return kernel_2d
    
    如果想要加速双边滤波计算速度，则要提前计算空间核函数
    def create_spatial_kernel(kernel_size, sigma, device):
    """
    预先计算空间权重核（考虑整张图像是均匀分布的，中心像素权重最高，向周边扩散权重减少）
    """
    def create_spatial_kernel(kernel_size, sigma):
    """创建空间距离核"""
    center = kernel_size // 2
    spatial_kernel = torch.zeros(kernel_size, kernel_size)

    for i in range(kernel_size):
        for j in range(kernel_size):
            distance_sq = (i - center) ** 2 + (j - center) ** 2
            spatial_kernel[i, j] = math.exp(-distance_sq / (2 * sigma ** 2))

    # 归一化
    spatial_kernel = spatial_kernel / spatial_kernel.sum()
    return spatial_kernel.view(1, 1, kernel_size, kernel_size)
2. 在训练完成后获得了空间，值域权重可视化图像
   ![17621382181893](https://github.com/user-attachments/assets/58dbaf19-df75-4d03-ac01-b3a4a3810801)

3. 下载了postdam的DSM数据集（12.14g），提取了其中一张RGB图像和对应的DSM对模型效果进行可视化，但是由于图像很大（108MB），GPU资源不足，对源文件进行patch-size切块操作：
    ```python
        def _process_by_patches(self, dsm, rgb, scaling, patch_size, transform, crs):
        """分块处理大图像"""
        _, h_hr, w_hr = dsm.shape

        # 计算块数
        h_patches = (h_hr + patch_size - 1) // patch_size
        w_patches = (w_hr + patch_size - 1) // patch_size

        patches = []

        for i in range(h_patches):
            for j in range(w_patches):
                # 计算当前块的起始和结束位置
                h_start = i * patch_size
                w_start = j * patch_size
                h_end = min(h_start + patch_size, h_hr)
                w_end = min(w_start + patch_size, w_hr)

                # 提取块
                dsm_patch = dsm[:, h_start:h_end, w_start:w_end].clone()
                rgb_patch = rgb[:, h_start:h_end, w_start:w_end].clone()

                print(f"块 ({i},{j}): DSM形状 {dsm_patch.shape}, RGB形状 {rgb_patch.shape}")

### 研究进度
1. 已经完成简化版双边滤波，计算在整个图像进行卷积，算出整体图像的空间权重后应用到强度权重图。

### 下周计划
1. 计划下周完成真正对逐个像素实现双边滤波器。并且完成提前算出空间权重的改进。
-----------------------------------------------------
## 2025年11月8日 赵仕灏
### 学习进度
1. 完成了完全的提前预计算空间权重的双边滤波器
    ```python
    spatial_kernel = create_gaussian_kernel(kernel_size, spatial_sigma, device)#提前创建了空间高斯核，只考虑像素间的空间距离，距离中心越近，权重越大，对于整张图像使用相同的空间权重分布，通过卷积一次性计算所有位置
    spatial_weights_x = F.conv2d(full_range_weight_x, spatial_kernel, padding=kernel_size//2)
    # 最终权重 = 范围权重 × 空间权重
    spatial_weights_x = F.conv2d(full_range_weight_x, spatial_kernel）
    ```
    在提出的提前计算高斯空间核方法，是对于整张图像使用相同的空间权重分布，从中心向四周指数衰：
[[0.003, 0.013, 0.022, 0.013, 0.003],
 [0.013, 0.059, 0.097, 0.059, 0.013],
 [0.022, 0.097, 0.159, 0.097, 0.022],
 [0.013, 0.059, 0.097, 0.059, 0.013],
 [0.003, 0.013, 0.022, 0.013, 0.003]]
    最后确保空间权重提供基础平滑：确保邻近像素有基本的影响力范围权重进行调制：在边缘处减小最终权重，在平坦处保持权重。
2. 初步进行了基于Lambertian模型的三维重建方法，Lambertian模型描述的是一种理想的漫反射方法，从任何角度看一个图像都是同样的亮度（这样的方法不能用于镜面反射，因为没有反射亮光）
数学模型为：I = k_d * I_l * max(0, n · l)，其中l是亮度，k_d是漫反射系数（在本项目中被归一化为了【0，1】，n是预测到的法向量（将法向量作为了一个方向的参考），n · l: 法向量与光源方向的点积
1. 在模型中加入了反射率特征提取卷积头： 
    ```python
    self.albedo_head = nn.Sequential(
        nn.Conv2d(feature_dim, 128, 3, padding=1),
        nn.LeakyReLU(0.2, inplace=True),
        nn.Conv2d(128, 64, 3, padding=1),
        nn.LeakyReLU(0.2, inplace=True),
        nn.Conv2d(64, 32, 3, padding=1),
        nn.LeakyReLU(0.2, inplace=True),
        nn.Conv2d(32, 3, 1),  # 输出RGB反照率
        nn.Sigmoid()
    )
    ```
    漫反射着色模型计算代码：
    ```python
    # 计算漫反射 (Lambertian)
    cos_theta = torch.sum(normals * light_direction, dim=1, keepdim=True)# [B, 1, H, W]
    cos_theta = torch.clamp(cos_theta, 0.0, 1.0)
    # 漫反射 = 反照率 * cos(光线与法线夹角)
    diffuse = albedo * cos_theta# Lambertian反射公式
    ```
    这个模型是基于物理的渲染（PBR）的，他将线性空间光照的计算在线性颜色空间进行，最后一步的Clamp可以看作是一种简单的色调映射，将HDR（高动态范围）值转换到LDR（低动态范围）用于显示。
    参考文献：
    SREVAS: Shading Based Surface Refinement under Varying Albedo and Specularity
    首轮结果：<img width="648" height="135" alt="f102b02a70300ce07dfe95dc3b4d077a_0" src="https://github.com/user-attachments/assets/512a0c83-345f-4d7d-9148-3c8f9f3d73f6" />

   出现了问题在于albedo和渲染后的图像都是黑白的，找到问题在于三个RGB通道的值非常接近或相同，模型没有学习到颜色变化
    Albedo channel means - R: 0.467, G: 0.481, B: 0.487
    Albedo channel stds - R: 0.005, G: 0.006, B: 0.005
    Rendered channel means - R: 0.362, G: 0.373, B: 0.377
    Rendered channel stds - R: 0.120, G: 0.124, B: 0.126
    Saved albedo rendering visualization for epoch 0
    反射率各通道均值非常接近：R:0.467, G:0.481, B:0.487
    反射率各通道标准差非常小：R:0.005, G:0.006, B:0.005
    采用了特别的初始化，为每一个颜色通道偏置了一个数值：
    ```python
        # 特别初始化最后一层，鼓励输出有颜色变化
        last_conv = self.albedo_head[-2]  # 倒数第二层是Conv2d
        nn.init.normal_(last_conv.weight, mean=0.0, std=0.02)
        if last_conv.bias is not None:
            # 初始化偏置为不同的值，鼓励颜色变化
            nn.init.constant_(last_conv.bias[0], 0.5)  # 红色通道
            nn.init.constant_(last_conv.bias[1], 0.3)  # 绿色通道  
            nn.init.constant_(last_conv.bias[2], 0.1)  # 蓝色通道
    ```
    同时我把参数--w_albedo_consistency反照率一致性权重和--w_albedo_smoothness反照率平滑性权重调整了，得到结果：
    <img width="648" height="604" alt="eb6b3383a850f7370d67390937845f6c" src="https://github.com/user-attachments/assets/ee373d01-d862-4e00-ba3c-72788650c15f" />

### 研究进度
1. 已经完成初步brdf，但现在的渲染图像很模糊，下一步要考虑对图像细节进行还原。
2. 完成了众多方法的可视化，包括每一轮结束后都对预测法向量和真实值进行对比，双边滤波平滑可视化，albedo和渲染可视化。
## 2025年11月27日 赵仕灏
### 学习进度
1. 阅读论文：A general albedo recovery approach for aerial photogrammetric images through inverse rendering，通过三维模型和多视角、多时间图像来重建并分离albedo，代码开源但没有复现成功。（缺少主文件）
<img width="760" height="836" alt="CBD19F296A539C39014FDE5904F61569" src="https://github.com/user-attachments/assets/828d1b15-597e-4d90-831c-bc169eea39de" />
2. 本周主要还是通过本征分解的方式分解出来航拍图像中的光照和albedo（通过mlp自动学习二阶球谐函数）。但是仍然存在问题，尽管损失函数仍然在下降，但是图像并不会去除阴影
   ![Uploading albedo_rendering_epoch_0045.png…]()
3. 通过可视化的方式首先确定代码有没有识别出来阴影部分到底是哪里，当前的方法仍然是亮度越低（越暗）就是阴影，需要改进

  ```python预测头
  self.albedo_head = nn.Sequential(
    nn.Conv2d(FEATURE_DIM, 64, 3, padding=1),
    nn.BatchNorm2d(64),
    nn.ReLU(inplace=True),
    nn.Conv2d(64, 3, 1),
    nn.Sigmoid()  # Albedo 范围 [0, 1]
).cuda()
self.light_mlp = nn.Sequential(
    nn.Linear(FEATURE_DIM, 128),
    nn.ReLU(inplace=True),
    nn.Linear(128, 64),
    nn.ReLU(inplace=True),
    nn.Linear(64, 27)  # 9 coeffs * 3 channels (RGB)
).cuda()
```
```python二街球谐基函数，通过mlp预测二阶球谐基系数
        # Level 1
        basis[:, 1] = self.c[1] * ny
        basis[:, 2] = self.c[2] * nz
        basis[:, 3] = self.c[3] * nx

        # Level 2
        basis[:, 4] = self.c[4] * nx * ny
        basis[:, 5] = self.c[5] * ny * nz
        basis[:, 6] = self.c[6] * (3 * nz * nz - 1)
        basis[:, 7] = self.c[7] * nx * nz
        basis[:, 8] = self.c[8] * (nx * nx - ny * ny)
```
目前的项目让然会存在albedo分解无效的情况，但重建效果却很好，损失也很平滑
### 研究进度
1. 继续精进albedo分离。
